{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definer\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import textmining\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    string = re.sub(r\"\\\\\", \"\", string)\n",
    "    string = re.sub(r\"\\'\", \"\", string)\n",
    "    string = re.sub(r\"\\\"\", \"\", string)\n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 100\n",
    "MAX_NB_WORDS = 20000\n",
    "EMBEDDING_DIM = 100\n",
    "VALIDATION_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/train.tsv', sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "Nd = np.zeros(5)\n",
    "print(Nd[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Shape of dataset ', (156060, 4))\n",
      "Index([u'PhraseId', u'SentenceId', u'Phrase', u'Sentiment'], dtype='object')\n",
      "('No. of unique classes', 5)\n"
     ]
    }
   ],
   "source": [
    "# reading data\n",
    "# df = pd.read_excel('dataset.xlsx')\n",
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)\n",
    "print('Shape of dataset ',df.shape)\n",
    "print(df.columns)\n",
    "print('No. of unique classes',len(set(df['Sentiment'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "macronum=sorted(set(df['Sentiment']))\n",
    "macro_to_id = dict((note, number) for number, note in enumerate(macronum))\n",
    "\n",
    "def fun(i):\n",
    "    return macro_to_id[i]\n",
    "\n",
    "df['Sentiment']=df['Sentiment'].apply(fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "labels = []\n",
    "# tdm = textmining.TermDocumentMatrix()\n",
    "for idx in df['Sentiment']:\n",
    "    labels.append(idx)\n",
    "\n",
    "for idx in range(df.Phrase.shape[0]):\n",
    "#     print(df.Phrase[idx])\n",
    "    text = df.Phrase[idx]\n",
    "    strr = clean_str(text)\n",
    "    Nd[labels[idx]] += len(strr.split())\n",
    "    texts.append(strr)\n",
    "#     tdm.add_doc(clean_str(text))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0453159041394\n",
      "0.174759707805\n",
      "0.50994489299\n",
      "0.210989363065\n",
      "0.0589901320005\n"
     ]
    }
   ],
   "source": [
    "pLabel0 = labels.count(0) * 1.0 / len(labels)\n",
    "pLabel1 = labels.count(1) * 1.0 / len(labels)\n",
    "pLabel2 = labels.count(2) * 1.0 / len(labels)\n",
    "pLabel3 = labels.count(3) * 1.0 / len(labels)\n",
    "pLabel4 = labels.count(4) * 1.0 / len(labels)\n",
    "print(pLabel0)\n",
    "print(pLabel1)\n",
    "print(pLabel2)\n",
    "print(pLabel3)\n",
    "print(pLabel4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cntr = 0\n",
    "# textLabel = []\n",
    "# trainData = []\n",
    "# for row in tdm.rows(cutoff=1):\n",
    "#     cntr = cntr + 1\n",
    "#     if cntr == 1:\n",
    "#         textLabel = row\n",
    "#     else:\n",
    "#         trainData.append(row)\n",
    "\n",
    "# print(len(trainData) , len(trainData[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 15241)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer()\n",
    "X = vec.fit_transform(texts)\n",
    "df = pd.DataFrame(X.toarray(), columns=vec.get_feature_names())\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AFTER Df being the document term frequency\n",
    "\n",
    "# P(label | text) === P(text | label) \n",
    "# CAlc P(text | label) for the whole VOCAB \n",
    "# So a matrix/dictionary of a['word'] = probability of 5 labels SO V*5 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "alp = 0.000000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 85270. 247523. 411176. 277216.  98250.]\n"
     ]
    }
   ],
   "source": [
    "print(Nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15241, 5)\n"
     ]
    }
   ],
   "source": [
    "xtf = np.zeros([15241,5])\n",
    "print(xtf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False ...  True False False]\n"
     ]
    }
   ],
   "source": [
    "lablls = np.asarray(labels)\n",
    "print(lablls == 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15241\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "for column in df:\n",
    "    labl = 0\n",
    "    \n",
    "    k = np.array(df[column])\n",
    "    while (labl < 5):\n",
    "        prrod = np.sum(np.dot(k,lablls==labl))\n",
    "        \"\"\"\n",
    "        sum of term of word defined by column for labl\n",
    "        and then\n",
    "        that sum (prrod) divided by all sum of word for th given label and then alp for\n",
    "        smoothening a hyper parameter.\n",
    "        \"\"\"\n",
    "        ans = (prrod + alp) * (1.0/( Nd[labl] + alp*k.shape[0] ))\n",
    "        xtf[j][labl] = ans\n",
    "        labl += 1\n",
    "    j = j + 1\n",
    "\n",
    "print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"This is a good pen\"\n",
    "\n",
    "sample_text = clean_str(sample_text)\n",
    "header_list = list(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.stdout = open('./out.csv', 'w')\n",
    "\n",
    "df = pd.read_csv('./data/test.tsv', sep='\\t', header=0)\n",
    "for idx in range(df.Phrase.shape[0]):\n",
    "    sample_text = df.Phrase[idx]\n",
    "    sample_text = clean_str(sample_text)\n",
    "    x = len(sample_text.split())\n",
    "    l0 = 1\n",
    "    l1 = 1\n",
    "    l2 = 1\n",
    "    l3 = 1\n",
    "    l4 = 1\n",
    "    for i in range(x):\n",
    "        if header_list.count(sample_text.split()[i]) > 0 :\n",
    "            l0 *= xtf[header_list.index(sample_text.split()[i])][0] * pLabel0\n",
    "            l1 *= xtf[header_list.index(sample_text.split()[i])][1] * pLabel1\n",
    "            l2 *= xtf[header_list.index(sample_text.split()[i])][2] * pLabel2\n",
    "            l3 *= xtf[header_list.index(sample_text.split()[i])][3] * pLabel3\n",
    "            l4 *= xtf[header_list.index(sample_text.split()[i])][4] * pLabel4\n",
    "    lp = np.zeros(5)\n",
    "    lp[0] = l0/ (l0 + l1 + l2 + l3 + l4)    \n",
    "    lp[1] = l1/ (l0 + l1 + l2 + l3 + l4)    \n",
    "    lp[2] = l2/ (l0 + l1 + l2 + l3 + l4)    \n",
    "    lp[3] = l3/ (l0 + l1 + l2 + l3 + l4)    \n",
    "    lp[4] = l4/ (l0 + l1 + l2 + l3 + l4)    \n",
    "    print(lp.argmax())\n",
    "\n",
    "# print(\"So the guessed rating is \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
