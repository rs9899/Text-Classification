{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definer\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import textmining\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    string = re.sub(r\"\\\\\", \"\", string)\n",
    "    string = re.sub(r\"\\'\", \"\", string)\n",
    "    string = re.sub(r\"\\\"\", \"\", string)\n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 100\n",
    "MAX_NB_WORDS = 20000\n",
    "EMBEDDING_DIM = 100\n",
    "VALIDATION_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/train.tsv', sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nd = np.zeros(5)\n",
    "print(Nd[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading data\n",
    "# df = pd.read_excel('dataset.xlsx')\n",
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)\n",
    "print('Shape of dataset ',df.shape)\n",
    "print(df.columns)\n",
    "print('No. of unique classes',len(set(df['Sentiment'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macronum=sorted(set(df['Sentiment']))\n",
    "macro_to_id = dict((note, number) for number, note in enumerate(macronum))\n",
    "\n",
    "def fun(i):\n",
    "    return macro_to_id[i]\n",
    "\n",
    "df['Sentiment']=df['Sentiment'].apply(fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "labels = []\n",
    "# tdm = textmining.TermDocumentMatrix()\n",
    "for idx in df['Sentiment']:\n",
    "    labels.append(idx)\n",
    "\n",
    "for idx in range(df.Phrase.shape[0]):\n",
    "#     print(df.Phrase[idx])\n",
    "    text = df.Phrase[idx]\n",
    "    strr = clean_str(text)\n",
    "    Nd[labels[idx]] += len(strr.split())\n",
    "    texts.append(strr)\n",
    "#     tdm.add_doc(clean_str(text))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pLabel0 = labels.count(0) * 1.0 / len(labels)\n",
    "pLabel1 = labels.count(1) * 1.0 / len(labels)\n",
    "pLabel2 = labels.count(2) * 1.0 / len(labels)\n",
    "pLabel3 = labels.count(3) * 1.0 / len(labels)\n",
    "pLabel4 = labels.count(4) * 1.0 / len(labels)\n",
    "print(pLabel0)\n",
    "print(pLabel1)\n",
    "print(pLabel2)\n",
    "print(pLabel3)\n",
    "print(pLabel4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cntr = 0\n",
    "# textLabel = []\n",
    "# trainData = []\n",
    "# for row in tdm.rows(cutoff=1):\n",
    "#     cntr = cntr + 1\n",
    "#     if cntr == 1:\n",
    "#         textLabel = row\n",
    "#     else:\n",
    "#         trainData.append(row)\n",
    "\n",
    "# print(len(trainData) , len(trainData[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer()\n",
    "X = vec.fit_transform(texts)\n",
    "df = pd.DataFrame(X.toarray(), columns=vec.get_feature_names())\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AFTER Df being the document term frequency\n",
    "\n",
    "# P(label | text) === P(text | label) \n",
    "# CAlc P(text | label) for the whole VOCAB \n",
    "# So a matrix/dictionary of a['word'] = probability of 5 labels SO V*5 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alp = 0.000000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtf = np.zeros([15241,5])\n",
    "print(xtf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lablls = np.asarray(labels)\n",
    "print(lablls == 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "for column in df:\n",
    "    labl = 0\n",
    "    \n",
    "    k = np.array(df[column])\n",
    "    while (labl < 5):\n",
    "        prrod = np.sum(np.dot(k,lablls==labl))\n",
    "        \"\"\"\n",
    "        sum of term of word defined by column for labl\n",
    "        and then\n",
    "        that sum (prrod) divided by all sum of word for th given label and then alp for\n",
    "        smoothening a hyper parameter.\n",
    "        \"\"\"\n",
    "        ans = (prrod + alp) * (1.0/( Nd[labl] + alp*k.shape[0] ))\n",
    "        xtf[j][labl] = ans\n",
    "        labl += 1\n",
    "    j = j + 1\n",
    "\n",
    "print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
